{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Pada bagian kita akan mencoba meng-implementasikan proses training object detection menggunakan tensorflow. Tutorial ini mengangkat studi kasus yaitu mendeteksi muka/wajah. sebagai persiapan awal sebelum meng-implentasikan proses training. Kita diharuskan menyiapkan dan menginstall dependencies yang dibutuhkan pada komputer kita. Tahapn persiapan tersebut dapat dilihat di link https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md  \n",
    "\n",
    "#####  - Tensorflow-script-model\n",
    "    - git clone https://github.com/tensorflow/models.git\n",
    "    - extract models\n",
    "    - buat folder dengan nama 'workshop_dsw'\n",
    "    - copy dan paste folder 'models' ke dalam folder 'tensorflow_dsw'\n",
    "        \n",
    "##### - Akses sebagai global variabel\n",
    "- Linux\n",
    "        \n",
    "        ```\n",
    "        #command-line :\n",
    "        export PYTHONPATH=\"/home/linux/workshop_dsw/models/research:/home/nodeflux/models/research/slim\n",
    "        # atau bashrc :\n",
    "        export PYTHONPATH=\"/home/linux/workshop_dsw/models/research:/home/nodeflux/models/research/slim:$PYTHONPATH\n",
    "        ```        \n",
    "- Windows \n",
    "        Go to System -> Advanced system settings -> Environment Variables -> New, and add a variable with the name PYTHON_PATH and these values.   \n",
    "        - Ubah 'PYTHON_PATH' menjadi PYTHONPATH\n",
    "        - Tambahkan %PYTHONPATH% di system varibles > PATH dan di user variables > PATH\n",
    "    ![](path_win.png)\n",
    "\n",
    "##### -Tensorflow\n",
    "\n",
    "```\n",
    "         # CPU: \n",
    "         pip install tensorflow         \n",
    "         # GPU: \n",
    "         pip install tensorflow-gpu\n",
    "         # jika menggunakan anaconda\n",
    "         conda install tensorflow==1.5.0\n",
    "\n",
    "```\n",
    "##### - cocoAPI\n",
    "\n",
    "```\n",
    "       pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\"\n",
    "```\n",
    "##### - Protobuf\n",
    "- Linux\n",
    "    \n",
    "    ```    \n",
    "        $ sudo apt-get install protobuf-compiler\n",
    "\n",
    "        # From workshop_dsw/models/research/        \n",
    "        $ cd workshop_dsw/models/research\n",
    "        $ protoc object_detection/protos/*.proto --python_out=.4\n",
    "        \n",
    "     ```\n",
    "        \n",
    "- Windows    \n",
    "    - Download [Windows v3.4.0 release “protoc-3.4.0-win32.zip”](https://github.com/google/protobuf/releases/download/v3.4.0/protoc-3.4.0-win32.zip) \n",
    "    - Extract the protoc-3.4.0-win32.zip di program files\n",
    "    - cd path\\to\\models\\research\n",
    "    - Execute the protobuf compile\n",
    "            ```\n",
    "                “C:\\Program Files\\protoc-3.4.0-win32\\bin\\protoc.exe” \n",
    "                object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "             ```\n",
    "        \n",
    "##### - Pretrained models\n",
    "- checkpoint models [ssd_mobilenet_v1_coco](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)\n",
    "- label map [label_ssd_mobilenet_v1_coco](    https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "## OUTLINE\n",
    "\n",
    "#### Setelah memastikan semua dependencies ter-install di lokal komputer, selanjutnya kita akan melakukan beberapa proses yaitu :\n",
    "1. Data preparation        \n",
    "2. Genearate Label_map(*.pbtx)                \n",
    "3. Genearate TFRecord (*.record)\n",
    "    - train.record\n",
    "    - valid.record\n",
    "4. File Config(.*config)\n",
    "5. Training\n",
    "6. Export model untuk inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Tahap 1: Data Preparation\n",
    "\n",
    "Pada bagian ini kita akan menyiapkan dataset untuk melatih model dalam mendeteksi muka. Data yang kita gunakan adalah dataset yang sudah diberi-label sebelumnya. \n",
    "\n",
    "Step yang dilakukan :\n",
    "1. File yang dibutuhkan antara lain :\n",
    "   - Download Wider dataset 'http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/'  \n",
    "   \n",
    "   ![](wider_face.jpg)\n",
    "   \n",
    "     File yang dibutuhan :\n",
    "         a. Wider Face Training Images\n",
    "         b. Wider Face Validation Images\n",
    "         c. Face annotations \n",
    "   - (optional) labels tools: (https://github.com/tzutalin/labelImg)\n",
    "   ![](label_tools.jpg)\n",
    "2. Extract file ke dalam folder yang sama:\n",
    "    contoh struktur folder:\n",
    "    \n",
    "         data------\n",
    "             -- WIDER_val\n",
    "             -- WIDER_train\n",
    "             -- wider_face_split\n",
    "          \n",
    "          *) Note : nama folder harus sama, Jika beda, maka pada script 'wider_to_xml_pascal.py' harus ikut diganti.\n",
    "3. Jalan script 'wider_to_xml_pascal.py' untuk mengkonversi format WIDER dataset ke dalam bentuk format pascal (.xml)\n",
    "\n",
    "##### Jalankan di command-line :\n",
    "\n",
    " ```bash\n",
    "\n",
    "       # arahkan path ke project direktori\n",
    "      cd C:\\Users\\rizky\\Documents\\dsw\\dsw_training\n",
    "      python wider_to_xml_pascal.py\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## Tahap 2 : Generate Label Map\n",
    "Label Map meruapakan sebuah file seperti format .json. File ini dibutuhkan tensorflow sebagai metadata dari dataset. \n",
    "contoh format :\n",
    "```\n",
    "    item{\n",
    "        id: 1\n",
    "        name: 'face' \n",
    "     }\n",
    "\n",
    "    item{\n",
    "        id: 2\n",
    "        name: 'body' \n",
    "     }\n",
    "```\n",
    "Pada step ini, kita akan menggunakan script 'generate_labelmap_xml_pascal.py' untuk meng-generate sebuah file bertipe *.pbtxt dari format pascal.\n",
    "\n",
    "###### Jalankan di command-line :\n",
    "- Linux\n",
    "```\n",
    "    # -l = file output\n",
    "    # -p = file xml format pascal\n",
    "    python generate_label_map_from_xml_pascal.py -p data/tf_wider_train/annotations/xmls -l wider_label_map.pbtxt\n",
    "```\n",
    "- Windows\n",
    "```\n",
    "   python generate_labelmap_xml_pascal.py -p data\\tf_wider_train\\annotations\\xmls -l wider_label_map.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Tahap 3: Generate TF Record\n",
    "\n",
    "TFRecord merupakan format untuk tensorflow yang sudah di enkapsulasi ke dalam bentuk tensor object. Isi tensor object tersebut equivalent dengan list dari dict untuk format python. Untuk setiap dict sendiri berisi list seperti: \n",
    "- list dari bbox (xmin,xmax,ymin,ymax) dalam bentuk rasio, \n",
    "- list dari nama/ class dari bbox\n",
    "- path \n",
    "- height dari image \n",
    "- widht dari image\n",
    "- dll.\n",
    "\n",
    "#### Contoh konversi :\n",
    "\n",
    "    ```\n",
    "    images_list = [{'height': 400,'width':400,\n",
    "                    'objects': [{'xmin': 12, \n",
    "                                'xmax': 24, \n",
    "                                'ymin': 230, \n",
    "                                'ymax': 256}, \n",
    "                    {'another bbox'},...]\n",
    "                   ]\n",
    "                   \n",
    "    writer = tf.python_io.TFRecordWriter('data/valid.tfrecord')\n",
    "    \n",
    "    for i, image in enumerate(images_list):\n",
    "        height = image['height']  # an int\n",
    "        width = image['width']  # an int\n",
    "        \n",
    "        bbox_Xmins = [float(bbox['xmin']/width) for bbox in image['objects']]  # list of floats\n",
    "        bbox_Ymins = [float(bbox['ymin']/height) for bbox in image['objects']]  # list of floats\n",
    "        \n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': dataset_util.int64_feature(height),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(bbox_Xmins)\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(bbox_Ymins)\n",
    "            \n",
    "        }))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "    ```\n",
    "\n",
    "\n",
    "##### Jalankan di command-line :\n",
    "\n",
    "- Linux :\n",
    "\n",
    "```\n",
    "# untuk data validasi \n",
    " python generate_tfrecord_from_xml_pascal.py \\\n",
    "--image_dir=/home/nodeflux/workshop/dsw/dsw_training/data/tf_wider_val/images \\\n",
    "--label_map_path=/home/nodeflux/workshop/dsw/dsw_training/wider_label_map.pbtxt \\\n",
    "--output_path=/home/nodeflux/workshop/dsw/dsw_training/wider_val.record \\\n",
    "--xml_dir=/home/nodeflux/workshop/dsw/dsw_training/data/tf_wider_val/annotations/xmls\n",
    "\n",
    "# untuk data train\n",
    " python generate_tfrecord_from_xml_pascal.py \\\n",
    "--image_dir=/home/nodeflux/workshop/dsw/dsw_training/data/tf_wider_train/images \\\n",
    "--label_map_path=/home/nodeflux/workshop/dsw/dsw_training/wider_label_map.pbtxt \\\n",
    "--output_path=/home/nodeflux/workshop/dsw/dsw_training/tf_wider_train.record \\\n",
    "--xml_dir=/home/nodeflux/workshop/dsw/dsw_training/data/tf_wider_train/annotations/xmls\n",
    "```\n",
    "\n",
    "- Windows\n",
    "     \n",
    "```\n",
    "     # untuk data validasi \n",
    "     python generate_tfrecord_from_xml_pascal.py --image_dir=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\data\\tf_wider_val\\images --label_map_path=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\wider_label_map.pbtxt --output_path=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\wider_val.record --xml_dir=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\data\\tf_wider_val\\annotations\\xmls\n",
    "\n",
    "    # untuk data train\n",
    "    python generate_tfrecord_from_xml_pascal.py --image_dir=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\data\\tf_wider_train\\images --label_map_path=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\wider_label_map.pbtxt --output_path=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\wider_train.record --xml_dir=C:\\Users\\rizky\\Documents\\dsw\\dsw_training\\data\\tf_wider_train\\annotations\\xmls\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Tahap 4 :  File Config\n",
    "\n",
    "Pada tahap ini, kita akan melakukan configurasi arsitektur untuk mendeteksi wajah. Pada kasus ini, kita gunakan ssd_mobilenet_v1_coco.config sebagai arsitektur model. \n",
    "\n",
    "#### Step pada tahap ini antara lain :\n",
    "\n",
    "\n",
    "1. Download ssd_mobilenet_v1_coco.config\n",
    "   Kita dapat mendwonload https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs atau mencari di direktori ```models/research/object_detection/samples/configs```, Kemudian copy dan paste file tersebut ke dalam folder project kita agar lebih mudah di akses. \n",
    "   \n",
    "2. Buka ssd_mobilenet_v1_coco.config menggunakan tools text editor. selanjutnya kita ubah beberapa line sesuai kebutuhan kita.\n",
    "    Adapun bagian-bagian yang diubah yaitu :\n",
    "\n",
    "    1. num_classes : 'num_classes: 90' menjadi 'num_classes: 1'\n",
    "    2. fine_tune_checkpoint : Jika kita menggunakan arsitektur yang sudah ada, baiknya kita menggunakan model sebelumnya sebagai fine_tune(transfer knowladge) untuk model kita yang baru.\n",
    "        ```\n",
    "        fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\n",
    "        ```\n",
    "\n",
    "    3. jumlah iterasi (num_steps): num_steps: 500 (bebas)\n",
    "\n",
    "    4. train_input_reader (path)\n",
    "\n",
    "        ```\n",
    "        train_input_reader: {\n",
    "          tf_record_input_reader {\n",
    "            input_path: \"wider_train.record\"\n",
    "          }\n",
    "          label_map_path: \"wider_label_map.pbtxt\"\n",
    "        }\n",
    "\n",
    "        ```\n",
    "\n",
    "    5. eval_input_reader (path)\n",
    "\n",
    "        ```\n",
    "        eval_input_reader: {\n",
    "          tf_record_input_reader {\n",
    "            input_path: \"wider_val.record\"\n",
    "          }\n",
    "          label_map_path: \"wider_label_map.pbtxt\"\n",
    "          shuffle: false\n",
    "          num_readers: 1\n",
    "        }\n",
    "\n",
    "\n",
    "        ```\n",
    "\n",
    "\n",
    "3.Simpan (save as).config baru\n",
    "\n",
    "##### Tips :\n",
    "\n",
    "In the data augmentation section of the training pipeline, some options can be added or removed to try and make the training better. Some of the options are listed here :\n",
    "- NormalizeImage normalize_image = 1;\n",
    "- RandomHorizontalFlip random_horizontal_flip = 2;\n",
    "- RandomPixelValueScale random_pixel_value_scale = 3;\n",
    "- RandomImageScale random_image_scale = 4;\n",
    "- RandomRGBtoGray random_rgb_to_gray = 5;\n",
    "- RandomAdjustBrightness random_adjust_brightness = 6;\n",
    "- RandomAdjustContrast random_adjust_contrast = 7;\n",
    "- RandomAdjustHue random_adjust_hue = 8;\n",
    "- RandomAdjustSaturation random_adjust_saturation = 9;\n",
    "- RandomDistortColor random_distort_color = 10;\n",
    "- RandomJitterBoxes random_jitter_boxes = 11;\n",
    "- RandomCropImage random_crop_image = 12;\n",
    "- RandomPadImage random_pad_image = 13;\n",
    "- RandomCropPadImage random_crop_pad_image = 14;\n",
    "- RandomCropToAspectRatio random_crop_to_aspect_ratio = 15;\n",
    "- RandomBlackPatches random_black_patches = 16;\n",
    "- RandomResizeMethod random_resize_method = 17;\n",
    "- ScaleBoxesToPixelCoordinates scale_boxes_to_pixel_coordinates = 18;\n",
    "- ResizeImage resize_image = 19;\n",
    "- SubtractChannelMean subtract_channel_mean = 20;\n",
    "- SSDRandomCrop ssd_random_crop = 21;\n",
    "- SSDRandomCropPad ssd_random_crop_pad = 22;\n",
    "- SSDRandomCropFixedAspectRatio ssd_random_crop_fixed_aspect_ratio = 23;\n",
    "\n",
    "Example : \n",
    "\n",
    "```\n",
    "\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_pixel_value_scale {\n",
    "      minval: 0.6\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "## Tahap 5 : Training\n",
    "Pada tahap ini kita sudah dapat melatih object detection menggunakan framework tensorflow menggunanakan WIDER dataset sebagai data train. Kita dapat melatih ini dengan tekhnologi CPU atau GPU tergantung kemampuan komputer kita dan installasi tensorflow.\n",
    "\n",
    "##### Note: sebelum memulai proses training, buat folder bernama 'training' untuk menyimpan model atau hasil proses training\n",
    "\n",
    "##### Untuk memulai training Jalankan di command-line :\n",
    "\n",
    "- Linux \n",
    "    ```\n",
    "\n",
    "    python ~/workshop_dsw/models/research/object_detection/train.py --logtostderr --pipeline_config_path=ssd_mobilenet_v1_face.config  --train_dir=training\n",
    "\n",
    "    ```\n",
    "\n",
    "- Windows\n",
    "\n",
    "    ```\n",
    "    python C:\\Users\\rizky\\Documents\\dsw\\models\\research\\object_detection\\train.py --logtostderr --pipeline_config_path=ssd_mobilenet_v1_coco.config  --train_dir=training\n",
    "\n",
    "    ```\n",
    "    \n",
    "    ![Gambar proses training](training_vis.jpg)\n",
    "\n",
    "Hasil dari model akan terbentuk 3 file checkpoint yang tersimpan di folder training:\n",
    "   \n",
    "    1. model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001\n",
    "    2. model.ckpt-${CHECKPOINT_NUMBER}.index\n",
    "    3. model.ckpt-${CHECKPOINT_NUMBER}.meta\n",
    "    \n",
    "   \n",
    "\n",
    "##### Note : Untuk mem-visualisasikan hasil traning, maka jalan perintahdi command-line:\n",
    "  \n",
    "  ```\n",
    "  $ tensorboard --logdir=training/\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "## Tahap 6 : Export model untuk inferencing\n",
    "\n",
    "Setelah melakukan pelatihan, tahap selanjutnya adalah meng-export model ke dalam bentuk graph proto (*.pb) \n",
    "dari file :\n",
    "```\n",
    "* model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001,\n",
    "* model.ckpt-${CHECKPOINT_NUMBER}.index\n",
    "* model.ckpt-${CHECKPOINT_NUMBER}.meta\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "##### Untuk memulai training Jalankan di command-line :\n",
    "\n",
    "\n",
    "- Linux\n",
    "    ``` \n",
    "    \n",
    "    python ~/workshop/dsw/models/research/object_detection/export_inference_graph.py \\\n",
    "        --input_type image_tensor \\\n",
    "        --pipeline_config_path ssd_mobilenet_v1_coco.config \\\n",
    "        --trained_checkpoint_prefix training/0/model.ckpt-500 \\\n",
    "        --output_directory training\n",
    "\n",
    "    ```\n",
    "- Windows :\n",
    " ```\n",
    "     python C:\\Users\\rizky\\Documents\\dsw\\models\\research\\object_detection\\export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix training/model.ckpt-500 --output_directory training\n",
    "\n",
    "    ```\n",
    "\n",
    "Hasil export berupa sebuah file bernama ```output_inference_graph.pb ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "## References :\n",
    "- https://github.com/qdraw/tensorflow-face-object-detector-tutorial\n",
    "- http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/\n",
    "- https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md\n",
    "- https://medium.com/@rohitrpatil/how-to-use-tensorflow-object-detection-api-on-windows-102ec8097699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
