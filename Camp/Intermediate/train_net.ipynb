{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a like VGG network with some modification in the network shape. VGG is well known architecture released by Oxford university. Based on ILSVRC-2014 submission, VGG secured the first and the second places in the localization and classification tasks respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/vgg1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/vgg2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install opencv conda:\n",
    "- conda install -c conda-forge opencv\n",
    "To install Tensorflow conda:\n",
    "- conda install -c conda-forge tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import walk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Gate\n",
    "\"placeholder\" is a gate for us to feed the TF graph.\n",
    "In this case, we want to classify face gender, So there are two classes: Male and female.\n",
    "The face image input is a color image in which 60 x 60 shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "x_input = tf.placeholder(dtype=tf.float32, shape=[None, 60, 60, 3], name='x_input')\n",
    "y_output = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='y_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build First Convolution Block\n",
    "Based on VGG architecture, the first block has 224x224x64 in shape. But, we built a placeholder for 60x60 image, so it will be modified to 60x60x64 in shape.\n",
    "60 is image width,\n",
    "60 is image heights, and\n",
    "64 is the num of filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 30, 30, 64) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_c1 = tf.nn.conv2d(x_input, tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b1_c1 += tf.Variable(tf.constant(0.05, shape=[64]))\n",
    "\n",
    "b1_c2 = tf.nn.conv2d(b1_c1, tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 64], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b1_c2 += tf.Variable(tf.constant(0.05, shape=[64]))\n",
    "\n",
    "b1_p = tf.nn.max_pool(b1_c2, [1, 2, 2, 1], [1,2,2,1], 'SAME')\n",
    "b1_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Second Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 15, 15, 128) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_c1 = tf.nn.conv2d(b1_p, tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b2_c1 += tf.Variable(tf.constant(0.05, shape=[128]))\n",
    "\n",
    "b2_c2 = tf.nn.conv2d(b2_c1, tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b2_c2 += tf.Variable(tf.constant(0.05, shape=[128]))\n",
    "\n",
    "b2_p = tf.nn.max_pool(b2_c2, [1, 2, 2, 1], [1,2,2,1], 'SAME')\n",
    "b2_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Third Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 8, 8, 256) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3_c1 = tf.nn.conv2d(b2_p, tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 256], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b3_c1 += tf.Variable(tf.constant(0.05, shape=[256]))\n",
    "\n",
    "b3_c2 = tf.nn.conv2d(b3_c1, tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 256], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b3_c2 += tf.Variable(tf.constant(0.05, shape=[256]))\n",
    "\n",
    "b3_c3 = tf.nn.conv2d(b3_c2, tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 256], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b3_c3 += tf.Variable(tf.constant(0.05, shape=[256]))\n",
    "\n",
    "b3_p = tf.nn.max_pool(b3_c3, [1, 2, 2, 1], [1,2,2,1], 'SAME')\n",
    "b3_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Fourth Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 4, 4, 512) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b4_c1 = tf.nn.conv2d(b3_p, tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 512], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b4_c1 += tf.Variable(tf.constant(0.05, shape=[512]))\n",
    "\n",
    "b4_c2 = tf.nn.conv2d(b4_c1, tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b4_c2 += tf.Variable(tf.constant(0.05, shape=[512]))\n",
    "\n",
    "b4_c3 = tf.nn.conv2d(b4_c2, tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=0.05)), [1,1,1,1], 'SAME')\n",
    "b4_c3 += tf.Variable(tf.constant(0.05, shape=[512]))\n",
    "\n",
    "b4_p = tf.nn.max_pool(b4_c3, [1, 2, 2, 1], [1,2,2,1], 'SAME')\n",
    "b4_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "our fourth convolution block has shape (?, 4, 4, 512). So its small enough to be flattened or in other word we dont need to make a fifth convolution block as like as VGG does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened = tf.contrib.layers.flatten(b4_p)\n",
    "fc1 = tf.matmul(flattened, tf.Variable(tf.truncated_normal([4*4*512, 500], stddev=0.05)))\n",
    "fc1 += tf.Variable(tf.constant(0.05, shape=[500]))\n",
    "fc2 = tf.matmul(fc1, tf.Variable(tf.truncated_normal([500, 10], stddev=0.05)))\n",
    "fc2 += tf.Variable(tf.constant(0.05, shape=[10]))\n",
    "fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softamx Function:\n",
    "![](assets/softmax.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.nn.softmax(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Optimizer\n",
    "loss: for counting the distance of predicted tensor with the true label, optimizer: for minimizing the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc2, labels=y_output))\n",
    "optimizer =  tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "y_pred = tf.argmax(output, axis=1)\n",
    "correct = tf.equal(y_pred, tf.argmax(y_output, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver and Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "session = tf.InteractiveSession()\n",
    "save_path = 'checkpoints/'\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pipeline\n",
    "In this section we will build a pipeline for feeding image to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fileNames(path):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in classes:\n",
    "    path = 'dataset/' + i + \"/\"\n",
    "    files = get_fileNames(path)\n",
    "    for j in files:\n",
    "        im = cv2.imread(path + j)\n",
    "        im = cv2.resize(im, (60, 60))\n",
    "        lbl = np.zeros(10)\n",
    "        lbl[int(i)] = 1.0\n",
    "        images.append(im)\n",
    "        labels.append(lbl)\n",
    "        \n",
    "images = np.array(images)\n",
    "images = images.astype(np.float32)\n",
    "images /= 255\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBKHgE5Ig/w9zmHRbl06+cAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a77e136d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(1, 600)\n",
    "plt.imshow(images[i])\n",
    "plt.show()\n",
    "print (labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(iterations):\n",
    "    im, lb = shuffle(images, labels)\n",
    "    train_images  = im[: 400]\n",
    "    train_labels = lb[: 400]\n",
    "    val_images = im[400:]\n",
    "    val_labels = lb[400:]\n",
    "    \n",
    "    best_loss = 100.0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        sign = '-'\n",
    "        \n",
    "        '''\n",
    "        for i in range(len(val_images)):\n",
    "            plt.imshow(train_images[i])\n",
    "            plt.show()\n",
    "            print train_labels[i]\n",
    "        '''\n",
    "    \n",
    "        train_feed_dict={x_input:train_images, y_output:train_labels}\n",
    "        val_feed_dict = {x_input:val_images, y_output:val_labels}\n",
    "        \n",
    "        session.run(optimizer, train_feed_dict)\n",
    "        train_loss = session.run(loss, train_feed_dict)\n",
    "        val_loss = session.run(loss, val_feed_dict)\n",
    "        train_accuracy = session.run(accuracy, train_feed_dict)\n",
    "        val_accuracy = session.run(accuracy, val_feed_dict)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            saver.save(sess=session, save_path=save_path + \"model1\")\n",
    "            best_loss = val_loss\n",
    "            sign = '*'\n",
    "        \n",
    "        print ('Epoch: {0}, Train Loss: {1:1.3}, Train Accu: {2:1.3}, Val Loss: {3:1.3}, Val Accu: {4:1.3}, {5}'.format(i, train_loss, train_accuracy, val_loss, val_accuracy, sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.98e+02, Train Accu: 0.112, Val Loss: 2.34e+02, Val Accu: 0.095, -\n",
      "Epoch: 1, Train Loss: 3.4e+02, Train Accu: 0.115, Val Loss: 3.85e+02, Val Accu: 0.09, -\n",
      "Epoch: 2, Train Loss: 4.08e+02, Train Accu: 0.14, Val Loss: 4.23e+02, Val Accu: 0.095, -\n",
      "Epoch: 3, Train Loss: 4.24e+02, Train Accu: 0.123, Val Loss: 4.08e+02, Val Accu: 0.105, -\n",
      "Epoch: 4, Train Loss: 4.15e+02, Train Accu: 0.132, Val Loss: 3.83e+02, Val Accu: 0.16, -\n",
      "Epoch: 5, Train Loss: 3.68e+02, Train Accu: 0.135, Val Loss: 3.34e+02, Val Accu: 0.17, -\n",
      "Epoch: 6, Train Loss: 3.03e+02, Train Accu: 0.195, Val Loss: 2.76e+02, Val Accu: 0.255, -\n",
      "Epoch: 7, Train Loss: 2.45e+02, Train Accu: 0.183, Val Loss: 2.25e+02, Val Accu: 0.25, -\n",
      "Epoch: 8, Train Loss: 1.24e+02, Train Accu: 0.22, Val Loss: 1.16e+02, Val Accu: 0.295, -\n",
      "Epoch: 9, Train Loss: 1.05e+02, Train Accu: 0.175, Val Loss: 1.02e+02, Val Accu: 0.135, -\n",
      "Epoch: 10, Train Loss: 1.02e+02, Train Accu: 0.195, Val Loss: 1.07e+02, Val Accu: 0.165, -\n",
      "Epoch: 11, Train Loss: 82.2, Train Accu: 0.177, Val Loss: 1.01e+02, Val Accu: 0.105, -\n",
      "Epoch: 12, Train Loss: 92.1, Train Accu: 0.162, Val Loss: 1.08e+02, Val Accu: 0.125, -\n",
      "Epoch: 13, Train Loss: 80.3, Train Accu: 0.305, Val Loss: 96.4, Val Accu: 0.275, *\n",
      "Epoch: 14, Train Loss: 84.2, Train Accu: 0.305, Val Loss: 98.0, Val Accu: 0.285, -\n",
      "Epoch: 15, Train Loss: 83.4, Train Accu: 0.298, Val Loss: 93.3, Val Accu: 0.29, *\n",
      "Epoch: 16, Train Loss: 77.4, Train Accu: 0.268, Val Loss: 87.6, Val Accu: 0.275, *\n",
      "Epoch: 17, Train Loss: 54.3, Train Accu: 0.36, Val Loss: 64.3, Val Accu: 0.32, *\n",
      "Epoch: 18, Train Loss: 35.6, Train Accu: 0.587, Val Loss: 44.9, Val Accu: 0.565, *\n",
      "Epoch: 19, Train Loss: 31.8, Train Accu: 0.598, Val Loss: 41.6, Val Accu: 0.55, *\n",
      "Epoch: 20, Train Loss: 30.6, Train Accu: 0.562, Val Loss: 41.6, Val Accu: 0.515, -\n",
      "Epoch: 21, Train Loss: 28.6, Train Accu: 0.575, Val Loss: 40.5, Val Accu: 0.55, *\n",
      "Epoch: 22, Train Loss: 25.6, Train Accu: 0.595, Val Loss: 37.9, Val Accu: 0.535, *\n",
      "Epoch: 23, Train Loss: 22.5, Train Accu: 0.582, Val Loss: 34.7, Val Accu: 0.53, *\n",
      "Epoch: 24, Train Loss: 17.4, Train Accu: 0.595, Val Loss: 28.6, Val Accu: 0.53, *\n",
      "Epoch: 25, Train Loss: 11.0, Train Accu: 0.668, Val Loss: 20.1, Val Accu: 0.575, *\n",
      "Epoch: 26, Train Loss: 8.59, Train Accu: 0.69, Val Loss: 15.4, Val Accu: 0.58, *\n",
      "Epoch: 27, Train Loss: 13.5, Train Accu: 0.582, Val Loss: 18.5, Val Accu: 0.505, -\n",
      "Epoch: 28, Train Loss: 14.1, Train Accu: 0.558, Val Loss: 18.3, Val Accu: 0.5, -\n",
      "Epoch: 29, Train Loss: 7.61, Train Accu: 0.69, Val Loss: 11.7, Val Accu: 0.605, *\n",
      "Epoch: 30, Train Loss: 4.51, Train Accu: 0.8, Val Loss: 9.92, Val Accu: 0.65, *\n",
      "Epoch: 31, Train Loss: 4.68, Train Accu: 0.77, Val Loss: 10.5, Val Accu: 0.64, -\n",
      "Epoch: 32, Train Loss: 4.66, Train Accu: 0.803, Val Loss: 10.7, Val Accu: 0.685, -\n",
      "Epoch: 33, Train Loss: 4.21, Train Accu: 0.82, Val Loss: 10.4, Val Accu: 0.695, -\n",
      "Epoch: 34, Train Loss: 3.67, Train Accu: 0.837, Val Loss: 10.6, Val Accu: 0.69, -\n",
      "Epoch: 35, Train Loss: 3.47, Train Accu: 0.82, Val Loss: 10.8, Val Accu: 0.695, -\n",
      "Epoch: 36, Train Loss: 3.33, Train Accu: 0.817, Val Loss: 10.7, Val Accu: 0.69, -\n",
      "Epoch: 37, Train Loss: 3.13, Train Accu: 0.832, Val Loss: 10.2, Val Accu: 0.695, -\n",
      "Epoch: 38, Train Loss: 2.86, Train Accu: 0.825, Val Loss: 9.56, Val Accu: 0.71, *\n",
      "Epoch: 39, Train Loss: 2.68, Train Accu: 0.848, Val Loss: 9.12, Val Accu: 0.7, *\n",
      "Epoch: 40, Train Loss: 2.6, Train Accu: 0.87, Val Loss: 8.87, Val Accu: 0.73, *\n",
      "Epoch: 41, Train Loss: 2.46, Train Accu: 0.877, Val Loss: 8.54, Val Accu: 0.74, *\n",
      "Epoch: 42, Train Loss: 2.23, Train Accu: 0.882, Val Loss: 7.97, Val Accu: 0.735, *\n",
      "Epoch: 43, Train Loss: 1.83, Train Accu: 0.887, Val Loss: 7.21, Val Accu: 0.75, *\n",
      "Epoch: 44, Train Loss: 1.4, Train Accu: 0.92, Val Loss: 6.45, Val Accu: 0.785, *\n",
      "Epoch: 45, Train Loss: 1.15, Train Accu: 0.942, Val Loss: 5.89, Val Accu: 0.795, *\n",
      "Epoch: 46, Train Loss: 0.965, Train Accu: 0.942, Val Loss: 5.46, Val Accu: 0.805, *\n",
      "Epoch: 47, Train Loss: 0.822, Train Accu: 0.95, Val Loss: 5.13, Val Accu: 0.825, *\n",
      "Epoch: 48, Train Loss: 0.717, Train Accu: 0.957, Val Loss: 4.99, Val Accu: 0.81, *\n",
      "Epoch: 49, Train Loss: 0.634, Train Accu: 0.95, Val Loss: 4.95, Val Accu: 0.82, *\n",
      "Epoch: 50, Train Loss: 0.557, Train Accu: 0.955, Val Loss: 4.97, Val Accu: 0.815, -\n",
      "Epoch: 51, Train Loss: 0.487, Train Accu: 0.96, Val Loss: 5.06, Val Accu: 0.79, -\n",
      "Epoch: 52, Train Loss: 0.438, Train Accu: 0.967, Val Loss: 5.15, Val Accu: 0.785, -\n",
      "Epoch: 53, Train Loss: 0.401, Train Accu: 0.967, Val Loss: 5.23, Val Accu: 0.79, -\n",
      "Epoch: 54, Train Loss: 0.369, Train Accu: 0.967, Val Loss: 5.28, Val Accu: 0.785, -\n",
      "Epoch: 55, Train Loss: 0.345, Train Accu: 0.967, Val Loss: 5.31, Val Accu: 0.785, -\n",
      "Epoch: 56, Train Loss: 0.322, Train Accu: 0.967, Val Loss: 5.31, Val Accu: 0.78, -\n",
      "Epoch: 57, Train Loss: 0.3, Train Accu: 0.967, Val Loss: 5.28, Val Accu: 0.785, -\n",
      "Epoch: 58, Train Loss: 0.269, Train Accu: 0.97, Val Loss: 5.19, Val Accu: 0.79, -\n",
      "Epoch: 59, Train Loss: 0.233, Train Accu: 0.97, Val Loss: 5.07, Val Accu: 0.795, -\n",
      "Epoch: 60, Train Loss: 0.193, Train Accu: 0.975, Val Loss: 4.94, Val Accu: 0.805, *\n",
      "Epoch: 61, Train Loss: 0.154, Train Accu: 0.983, Val Loss: 4.8, Val Accu: 0.815, *\n",
      "Epoch: 62, Train Loss: 0.116, Train Accu: 0.985, Val Loss: 4.66, Val Accu: 0.815, *\n",
      "Epoch: 63, Train Loss: 0.0739, Train Accu: 0.985, Val Loss: 4.54, Val Accu: 0.825, *\n",
      "Epoch: 64, Train Loss: 0.0376, Train Accu: 0.99, Val Loss: 4.43, Val Accu: 0.82, *\n",
      "Epoch: 65, Train Loss: 0.0195, Train Accu: 0.993, Val Loss: 4.34, Val Accu: 0.825, *\n",
      "Epoch: 66, Train Loss: 0.00885, Train Accu: 0.995, Val Loss: 4.28, Val Accu: 0.835, *\n",
      "Epoch: 67, Train Loss: 0.00544, Train Accu: 0.998, Val Loss: 4.23, Val Accu: 0.835, *\n",
      "Epoch: 68, Train Loss: 0.00615, Train Accu: 0.998, Val Loss: 4.19, Val Accu: 0.835, *\n",
      "Epoch: 69, Train Loss: 0.00734, Train Accu: 0.998, Val Loss: 4.17, Val Accu: 0.835, *\n",
      "Epoch: 70, Train Loss: 0.00767, Train Accu: 0.998, Val Loss: 4.15, Val Accu: 0.835, *\n",
      "Epoch: 71, Train Loss: 0.00707, Train Accu: 0.998, Val Loss: 4.14, Val Accu: 0.835, *\n",
      "Epoch: 72, Train Loss: 0.00579, Train Accu: 0.998, Val Loss: 4.13, Val Accu: 0.83, *\n",
      "Epoch: 73, Train Loss: 0.00424, Train Accu: 0.998, Val Loss: 4.12, Val Accu: 0.83, *\n",
      "Epoch: 74, Train Loss: 0.00301, Train Accu: 1.0, Val Loss: 4.1, Val Accu: 0.83, *\n",
      "Epoch: 75, Train Loss: 0.00238, Train Accu: 1.0, Val Loss: 4.09, Val Accu: 0.83, *\n",
      "Epoch: 76, Train Loss: 0.00194, Train Accu: 1.0, Val Loss: 4.08, Val Accu: 0.835, *\n",
      "Epoch: 77, Train Loss: 0.00145, Train Accu: 1.0, Val Loss: 4.07, Val Accu: 0.835, *\n",
      "Epoch: 78, Train Loss: 0.000984, Train Accu: 1.0, Val Loss: 4.06, Val Accu: 0.835, *\n",
      "Epoch: 79, Train Loss: 0.000654, Train Accu: 1.0, Val Loss: 4.05, Val Accu: 0.835, *\n",
      "Epoch: 80, Train Loss: 0.00046, Train Accu: 1.0, Val Loss: 4.05, Val Accu: 0.84, *\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-332d685530f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-2ed1a6cb9c6e>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"model1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1571\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
